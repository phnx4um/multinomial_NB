{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list = []\n",
    "sentiment_list = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(\"./ML - Assignment 2/naive_bayes_data.txt\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        line_list = line.split(' ', 3)\n",
    "        document = line_list[3].rstrip('\\n') \n",
    "        sentiment = line_list[1] \n",
    "        \n",
    "        document_list.append(document)\n",
    "        sentiment_list.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11914\n",
      "11914\n"
     ]
    }
   ],
   "source": [
    "print(len(document_list))\n",
    "print(len(sentiment_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i bought this album because i loved the title song . it 's such a great song , how bad can the rest of the album be , right ? well , the rest of the songs are just filler and are n't worth the money i paid for this . it 's either shameless bubblegum or oversentimentalized depressing tripe . kenny chesney is a popular artist and as a result he is in the cookie cutter category of the nashville music scene . he 's gotta pump out the albums so the record company can keep lining their pockets while the suckers out there keep buying this garbage to perpetuate more garbage coming out of that town . i 'll get down off my soapbox now . but country music really needs to get back to it 's roots and stop this pop nonsense . what country music really is and what it is considered to be by mainstream are two different things . \", 'i was misled and thought i was buying the entire cd and it contains one song ', \"i have introduced many of my ell , high school students to lois lowery and the depth of her characters . she is a brilliant writer and capable of inspiring fierce passion in her readers as they encounter shocking details of her utopian worlds . i was anxious to read this companion novel and had planned to share it with my class this january . although the series is written for 6th graders and older , this book 's simplicity , in its message , language and writing style will inspire no one . i am sadly disappointed \", 'anything you purchase in the left behind series is an excellent read . these books are great and very close to the bible . i have the entire set . amazon is a great shopping site and they ship fast . i would recommend these to any christian wanting to know about what to expect during the return of christ ! they are fiction but still makes a good point ', 'i loved these movies , and i cant wiat for the third one ! very funny , not suitable for chilren ']\n",
      "['neg', 'neg', 'neg', 'pos', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(document_list[:5])  #document_list: list of strings i.e. documents\n",
    "print(sentiment_list[:5]) #sentiment_list: list of strings(pos|neg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing sets\n",
    "train_X = document_list[:int(0.8*len(document_list))] \n",
    "train_y = sentiment_list[:int(0.8*len(sentiment_list))]\n",
    "\n",
    "validate_X = document_list[int(0.8*len(document_list)):] \n",
    "validate_y = sentiment_list[int(0.8*len(sentiment_list)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9531\n",
      "2383\n",
      "TOTAL LENGTH: 11914\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))\n",
    "print(len(validate_X))\n",
    "\n",
    "print(f\"TOTAL LENGTH: {len(train_X) + len(validate_X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i bought this album because i loved the title song . it 's such a great song , how bad can the rest of the album be , right ? well , the rest of the songs are just filler and are n't worth the money i paid for this . it 's either shameless bubblegum or oversentimentalized depressing tripe . kenny chesney is a popular artist and as a result he is in the cookie cutter category of the nashville music scene . he 's gotta pump out the albums so the record company can keep lining their pockets while the suckers out there keep buying this garbage to perpetuate more garbage coming out of that town . i 'll get down off my soapbox now . but country music really needs to get back to it 's roots and stop this pop nonsense . what country music really is and what it is considered to be by mainstream are two different things . \", 'i was misled and thought i was buying the entire cd and it contains one song ']\n",
      "['neg', 'neg']\n"
     ]
    }
   ],
   "source": [
    "print(train_X[:2])\n",
    "print(train_y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\phnx4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "'''\n",
    "now we will work only with the training data\n",
    "This function remove stopwords and puntuation from all of the training data\n",
    "\n",
    "INPUT: takes a string \n",
    "OUTPUT: and returns list of tokens(after removing the stops words and puntuation)\n",
    "'''\n",
    "def rev_to_words(review):\n",
    "    #remove punctuation\n",
    "    review = ''.join([c for c in review if c not in punctuation])\n",
    "    #split words\n",
    "    words = review.split()\n",
    "    #remove stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought',\n",
       " 'album',\n",
       " 'loved',\n",
       " 'title',\n",
       " 'song',\n",
       " 'great',\n",
       " 'song',\n",
       " 'bad',\n",
       " 'rest',\n",
       " 'album',\n",
       " 'right',\n",
       " 'well',\n",
       " 'rest',\n",
       " 'songs',\n",
       " 'filler',\n",
       " 'nt',\n",
       " 'worth',\n",
       " 'money',\n",
       " 'paid',\n",
       " 'either',\n",
       " 'shameless',\n",
       " 'bubblegum',\n",
       " 'oversentimentalized',\n",
       " 'depressing',\n",
       " 'tripe',\n",
       " 'kenny',\n",
       " 'chesney',\n",
       " 'popular',\n",
       " 'artist',\n",
       " 'result',\n",
       " 'cookie',\n",
       " 'cutter',\n",
       " 'category',\n",
       " 'nashville',\n",
       " 'music',\n",
       " 'scene',\n",
       " 'gotta',\n",
       " 'pump',\n",
       " 'albums',\n",
       " 'record',\n",
       " 'company',\n",
       " 'keep',\n",
       " 'lining',\n",
       " 'pockets',\n",
       " 'suckers',\n",
       " 'keep',\n",
       " 'buying',\n",
       " 'garbage',\n",
       " 'perpetuate',\n",
       " 'garbage',\n",
       " 'coming',\n",
       " 'town',\n",
       " 'get',\n",
       " 'soapbox',\n",
       " 'country',\n",
       " 'music',\n",
       " 'really',\n",
       " 'needs',\n",
       " 'get',\n",
       " 'back',\n",
       " 'roots',\n",
       " 'stop',\n",
       " 'pop',\n",
       " 'nonsense',\n",
       " 'country',\n",
       " 'music',\n",
       " 'really',\n",
       " 'considered',\n",
       " 'mainstream',\n",
       " 'two',\n",
       " 'different',\n",
       " 'things']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_to_words(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function converts the list of strings to list of list(of words from string with stop words and punctuation removed)\n",
    "def process_data(train_list):\n",
    "    train_list = [rev_to_words(review) for review in train_list]\n",
    "    return train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = process_data(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bought', 'album', 'loved', 'title', 'song', 'great', 'song', 'bad', 'rest', 'album', 'right', 'well', 'rest', 'songs', 'filler', 'nt', 'worth', 'money', 'paid', 'either', 'shameless', 'bubblegum', 'oversentimentalized', 'depressing', 'tripe', 'kenny', 'chesney', 'popular', 'artist', 'result', 'cookie', 'cutter', 'category', 'nashville', 'music', 'scene', 'gotta', 'pump', 'albums', 'record', 'company', 'keep', 'lining', 'pockets', 'suckers', 'keep', 'buying', 'garbage', 'perpetuate', 'garbage', 'coming', 'town', 'get', 'soapbox', 'country', 'music', 'really', 'needs', 'get', 'back', 'roots', 'stop', 'pop', 'nonsense', 'country', 'music', 'really', 'considered', 'mainstream', 'two', 'different', 'things'], ['misled', 'thought', 'buying', 'entire', 'cd', 'contains', 'one', 'song'], ['introduced', 'many', 'ell', 'high', 'school', 'students', 'lois', 'lowery', 'depth', 'characters', 'brilliant', 'writer', 'capable', 'inspiring', 'fierce', 'passion', 'readers', 'encounter', 'shocking', 'details', 'utopian', 'worlds', 'anxious', 'read', 'companion', 'novel', 'planned', 'share', 'class', 'january', 'although', 'series', 'written', '6th', 'graders', 'older', 'book', 'simplicity', 'message', 'language', 'writing', 'style', 'inspire', 'one', 'sadly', 'disappointed'], ['anything', 'purchase', 'left', 'behind', 'series', 'excellent', 'read', 'books', 'great', 'close', 'bible', 'entire', 'set', 'amazon', 'great', 'shopping', 'site', 'ship', 'fast', 'would', 'recommend', 'christian', 'wanting', 'know', 'expect', 'return', 'christ', 'fiction', 'still', 'makes', 'good', 'point'], ['loved', 'movies', 'cant', 'wiat', 'third', 'one', 'funny', 'suitable', 'chilren']]\n",
      "9531\n"
     ]
    }
   ],
   "source": [
    "print(train_X[:5])\n",
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter() \n",
    "for words in train_X:\n",
    "    c.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48193\n"
     ]
    }
   ],
   "source": [
    "print(len(c)) #Unique words in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nt', 7043),\n",
       " ('one', 5301),\n",
       " ('like', 4061),\n",
       " ('book', 3688),\n",
       " ('would', 3517),\n",
       " ('good', 3100),\n",
       " ('get', 2874),\n",
       " ('great', 2844),\n",
       " ('camera', 2758),\n",
       " ('time', 2657),\n",
       " ('even', 2344),\n",
       " ('use', 2238),\n",
       " ('really', 2145),\n",
       " ('movie', 2127),\n",
       " ('well', 2113),\n",
       " ('much', 2081),\n",
       " ('also', 2081),\n",
       " ('first', 2015),\n",
       " ('could', 1881),\n",
       " ('product', 1745),\n",
       " ('better', 1678),\n",
       " ('film', 1663),\n",
       " ('new', 1627),\n",
       " ('album', 1621),\n",
       " ('work', 1618),\n",
       " ('many', 1589),\n",
       " ('way', 1505),\n",
       " ('best', 1484),\n",
       " ('love', 1438),\n",
       " ('make', 1410),\n",
       " ('cd', 1393),\n",
       " ('still', 1384),\n",
       " ('see', 1381),\n",
       " ('two', 1374),\n",
       " ('people', 1374),\n",
       " ('read', 1370),\n",
       " ('back', 1349),\n",
       " ('buy', 1338),\n",
       " ('music', 1308),\n",
       " ('used', 1303),\n",
       " ('think', 1272),\n",
       " ('never', 1257),\n",
       " ('know', 1230),\n",
       " ('bought', 1229),\n",
       " ('want', 1199),\n",
       " ('years', 1194),\n",
       " ('little', 1167),\n",
       " ('find', 1158),\n",
       " ('go', 1097),\n",
       " ('got', 1091),\n",
       " ('software', 1090),\n",
       " ('say', 1061),\n",
       " ('another', 1050),\n",
       " ('2', 1048),\n",
       " ('take', 1009),\n",
       " ('made', 1007),\n",
       " ('version', 1001),\n",
       " ('quality', 1000),\n",
       " ('lens', 982),\n",
       " ('however', 977),\n",
       " ('using', 976),\n",
       " ('bad', 975),\n",
       " ('story', 964),\n",
       " ('life', 958),\n",
       " ('every', 953),\n",
       " ('ever', 947),\n",
       " ('need', 935),\n",
       " ('money', 933),\n",
       " ('found', 913),\n",
       " ('easy', 907),\n",
       " ('since', 893),\n",
       " ('songs', 890),\n",
       " ('lot', 888),\n",
       " ('dvd', 887),\n",
       " ('thing', 881),\n",
       " ('pictures', 879),\n",
       " ('without', 873),\n",
       " ('ca', 870),\n",
       " ('program', 869),\n",
       " ('song', 868),\n",
       " ('old', 842),\n",
       " ('something', 829),\n",
       " ('going', 809),\n",
       " ('may', 797),\n",
       " ('long', 795),\n",
       " ('though', 793),\n",
       " ('problem', 792),\n",
       " ('recommend', 787),\n",
       " ('times', 784),\n",
       " ('makes', 769),\n",
       " ('give', 762),\n",
       " ('right', 761),\n",
       " ('day', 748),\n",
       " ('far', 735),\n",
       " ('put', 733),\n",
       " ('enough', 732),\n",
       " ('works', 731),\n",
       " ('nothing', 727),\n",
       " ('look', 717),\n",
       " ('3', 709),\n",
       " ('hard', 709),\n",
       " ('end', 707),\n",
       " ('us', 699),\n",
       " ('different', 692),\n",
       " ('thought', 690),\n",
       " ('actually', 690),\n",
       " ('1', 689),\n",
       " ('things', 685),\n",
       " ('always', 683),\n",
       " ('price', 676),\n",
       " ('last', 663),\n",
       " ('must', 663),\n",
       " ('set', 662),\n",
       " ('worth', 660),\n",
       " ('year', 659),\n",
       " ('quot', 659),\n",
       " ('feel', 658),\n",
       " ('computer', 651),\n",
       " ('seems', 645),\n",
       " ('around', 641),\n",
       " ('come', 640),\n",
       " ('almost', 637),\n",
       " ('world', 631),\n",
       " ('real', 630),\n",
       " ('5', 630),\n",
       " ('video', 620),\n",
       " ('reading', 608),\n",
       " ('anyone', 607),\n",
       " ('big', 607),\n",
       " ('nice', 607),\n",
       " ('pretty', 603),\n",
       " ('anything', 598),\n",
       " ('looking', 595),\n",
       " ('sure', 589),\n",
       " ('several', 588),\n",
       " ('sound', 584),\n",
       " ('help', 581),\n",
       " ('try', 578),\n",
       " ('bit', 578),\n",
       " ('small', 577),\n",
       " ('quite', 576),\n",
       " ('yet', 574),\n",
       " ('original', 573),\n",
       " ('characters', 560),\n",
       " ('books', 558),\n",
       " ('digital', 558),\n",
       " ('part', 556),\n",
       " ('away', 553),\n",
       " ('fact', 552),\n",
       " ('point', 550),\n",
       " ('able', 547),\n",
       " ('case', 542),\n",
       " ('excellent', 540),\n",
       " ('everything', 540),\n",
       " ('man', 539),\n",
       " ('amazon', 538),\n",
       " ('takes', 537),\n",
       " ('hair', 537),\n",
       " ('might', 537),\n",
       " ('keep', 536),\n",
       " ('picture', 535),\n",
       " ('said', 534),\n",
       " ('show', 533),\n",
       " ('less', 533),\n",
       " ('getting', 532),\n",
       " ('support', 529),\n",
       " ('canon', 525),\n",
       " ('light', 525),\n",
       " ('battery', 524),\n",
       " ('trying', 521),\n",
       " ('purchased', 521),\n",
       " ('problems', 519),\n",
       " ('done', 514),\n",
       " ('instead', 513),\n",
       " ('4', 511),\n",
       " ('reviews', 506),\n",
       " ('probably', 505),\n",
       " ('three', 505),\n",
       " ('series', 499),\n",
       " ('system', 499),\n",
       " ('came', 499),\n",
       " ('tried', 494),\n",
       " ('let', 493),\n",
       " ('high', 491),\n",
       " ('least', 491),\n",
       " ('live', 484),\n",
       " ('especially', 482),\n",
       " ('stars', 479),\n",
       " ('took', 478),\n",
       " ('home', 478),\n",
       " ('second', 476),\n",
       " ('seen', 476),\n",
       " ('full', 471),\n",
       " ('days', 470),\n",
       " ('author', 469),\n",
       " ('features', 468),\n",
       " ('character', 465),\n",
       " ('play', 462),\n",
       " ('comes', 456),\n",
       " ('10', 454),\n",
       " ('movies', 453),\n",
       " ('highly', 451),\n",
       " ('fan', 449),\n",
       " ('review', 448),\n",
       " ('course', 445),\n",
       " ('believe', 444),\n",
       " ('whole', 444),\n",
       " ('rather', 443),\n",
       " ('written', 442),\n",
       " ('wanted', 442),\n",
       " ('next', 438),\n",
       " ('someone', 435),\n",
       " ('fine', 435),\n",
       " ('making', 428),\n",
       " ('although', 423),\n",
       " ('others', 423),\n",
       " ('months', 422),\n",
       " ('fun', 418),\n",
       " ('simply', 416),\n",
       " ('ago', 414),\n",
       " ('reason', 413),\n",
       " ('either', 412),\n",
       " ('start', 412),\n",
       " ('true', 409),\n",
       " ('job', 408),\n",
       " ('screen', 408),\n",
       " ('purchase', 407),\n",
       " ('wrong', 405),\n",
       " ('band', 397),\n",
       " ('already', 396),\n",
       " ('else', 391),\n",
       " ('interesting', 391),\n",
       " ('disappointed', 390),\n",
       " ('etc', 390),\n",
       " ('maybe', 390),\n",
       " ('image', 390),\n",
       " ('minutes', 390),\n",
       " ('kind', 389),\n",
       " ('heard', 388),\n",
       " ('family', 387),\n",
       " ('watch', 387),\n",
       " ('track', 385),\n",
       " ('windows', 384),\n",
       " ('learn', 383),\n",
       " ('later', 382),\n",
       " ('understand', 379),\n",
       " ('seem', 375),\n",
       " ('place', 373),\n",
       " ('short', 373),\n",
       " ('flash', 372),\n",
       " ('tell', 371),\n",
       " ('buying', 369),\n",
       " ('listen', 369),\n",
       " ('finally', 368),\n",
       " ('enjoy', 366),\n",
       " ('photos', 365),\n",
       " ('went', 364),\n",
       " ('simple', 363),\n",
       " ('overall', 361),\n",
       " ('star', 360),\n",
       " ('wonderful', 360),\n",
       " ('worked', 359),\n",
       " ('children', 359),\n",
       " ('often', 357),\n",
       " ('kids', 357),\n",
       " ('perfect', 356),\n",
       " ('waste', 353),\n",
       " ('together', 353),\n",
       " ('happy', 353),\n",
       " ('couple', 352),\n",
       " ('wo', 352),\n",
       " ('free', 351),\n",
       " ('run', 349),\n",
       " ('writing', 348),\n",
       " ('power', 347),\n",
       " ('completely', 347),\n",
       " ('voice', 347),\n",
       " ('definitely', 345),\n",
       " ('experience', 344),\n",
       " ('young', 344),\n",
       " ('history', 343),\n",
       " ('top', 342),\n",
       " ('word', 342),\n",
       " ('left', 339),\n",
       " ('working', 339),\n",
       " ('feature', 339),\n",
       " ('card', 338),\n",
       " ('gets', 337),\n",
       " ('stuff', 334),\n",
       " ('favorite', 333),\n",
       " ('game', 333),\n",
       " ('products', 332),\n",
       " ('batteries', 332),\n",
       " ('low', 330),\n",
       " ('taking', 330),\n",
       " ('rock', 330),\n",
       " ('hours', 330),\n",
       " ('6', 328),\n",
       " ('tracks', 327),\n",
       " ('return', 325),\n",
       " ('started', 324),\n",
       " ('plot', 324),\n",
       " ('mind', 323),\n",
       " ('information', 323),\n",
       " ('along', 322),\n",
       " ('given', 322),\n",
       " ('collection', 322),\n",
       " ('night', 322),\n",
       " ('called', 321),\n",
       " ('beautiful', 319),\n",
       " ('turn', 318),\n",
       " ('worst', 317),\n",
       " ('size', 316),\n",
       " ('classic', 316),\n",
       " ('everyone', 316),\n",
       " ('style', 315),\n",
       " ('goes', 314),\n",
       " ('sony', 314),\n",
       " ('order', 312),\n",
       " ('rest', 311),\n",
       " ('looks', 310),\n",
       " ('gave', 310),\n",
       " ('performance', 310),\n",
       " ('loved', 309),\n",
       " ('black', 309),\n",
       " ('head', 308),\n",
       " ('person', 308),\n",
       " ('poor', 308),\n",
       " ('microsoft', 307),\n",
       " ('close', 306),\n",
       " ('easily', 306),\n",
       " ('amazing', 306),\n",
       " ('saw', 306),\n",
       " ('cannot', 306),\n",
       " ('gives', 305),\n",
       " ('says', 303),\n",
       " ('cameras', 301),\n",
       " ('service', 301),\n",
       " ('needed', 300),\n",
       " ('office', 298),\n",
       " ('clear', 298),\n",
       " ('files', 297),\n",
       " ('save', 297),\n",
       " ('idea', 296),\n",
       " ('sense', 296),\n",
       " ('lost', 296),\n",
       " ('albums', 295),\n",
       " ('hear', 294),\n",
       " ('ok', 294),\n",
       " ('memory', 294),\n",
       " ('water', 293),\n",
       " ('past', 293),\n",
       " ('entire', 292),\n",
       " ('yes', 291),\n",
       " ('season', 289),\n",
       " ('line', 289),\n",
       " ('scene', 288),\n",
       " ('box', 288),\n",
       " ('today', 287),\n",
       " ('user', 287),\n",
       " ('previous', 286),\n",
       " ('truly', 286),\n",
       " ('main', 285),\n",
       " ('zoom', 283),\n",
       " ('sounds', 283),\n",
       " ('funny', 282),\n",
       " ('john', 282),\n",
       " ('taken', 281),\n",
       " ('name', 281),\n",
       " ('company', 280),\n",
       " ('shots', 280),\n",
       " ('example', 279),\n",
       " ('change', 279),\n",
       " ('difficult', 279),\n",
       " ('complete', 279),\n",
       " ('available', 278),\n",
       " ('playing', 277),\n",
       " ('open', 276),\n",
       " ('decided', 275),\n",
       " ('slow', 275),\n",
       " ('hand', 275),\n",
       " ('piece', 275),\n",
       " ('pages', 274),\n",
       " ('scenes', 274),\n",
       " ('needs', 273),\n",
       " ('item', 273),\n",
       " ('sometimes', 273),\n",
       " ('words', 273),\n",
       " ('watching', 273),\n",
       " ('fast', 272),\n",
       " ('wish', 272),\n",
       " ('page', 272),\n",
       " ('guess', 272),\n",
       " ('films', 271),\n",
       " ('images', 271),\n",
       " ('hope', 271),\n",
       " ('school', 269),\n",
       " ('absolutely', 269),\n",
       " ('cover', 269),\n",
       " ('four', 269),\n",
       " ('perhaps', 269),\n",
       " ('customer', 269),\n",
       " ('number', 268),\n",
       " ('20', 267),\n",
       " ('american', 267),\n",
       " ('photo', 266),\n",
       " ('told', 266),\n",
       " ('white', 264),\n",
       " ('fit', 264),\n",
       " ('war', 263),\n",
       " ('half', 263),\n",
       " ('certainly', 262),\n",
       " ('novel', 261),\n",
       " ('reader', 260),\n",
       " ('single', 260),\n",
       " ('write', 258),\n",
       " ('women', 258),\n",
       " ('guy', 258),\n",
       " ('type', 258),\n",
       " ('pay', 256),\n",
       " ('played', 255),\n",
       " ('quickly', 255),\n",
       " ('adobe', 254),\n",
       " ('side', 253),\n",
       " ('deal', 253),\n",
       " ('business', 252),\n",
       " ('action', 252),\n",
       " ('become', 251),\n",
       " ('plus', 251),\n",
       " ('vista', 250),\n",
       " ('hold', 250),\n",
       " ('results', 249),\n",
       " ('longer', 249),\n",
       " ('extremely', 248),\n",
       " ('learning', 248),\n",
       " ('matter', 248),\n",
       " ('weeks', 248),\n",
       " ('felt', 247),\n",
       " ('unfortunately', 247),\n",
       " ('release', 247),\n",
       " ('check', 247),\n",
       " ('view', 247),\n",
       " ('friend', 247),\n",
       " ('face', 244),\n",
       " ('huge', 244),\n",
       " ('upgrade', 243),\n",
       " ('acting', 243),\n",
       " ('add', 243),\n",
       " ('focus', 243),\n",
       " ('call', 243),\n",
       " ('special', 243),\n",
       " ('shows', 243),\n",
       " ('thinking', 242),\n",
       " ('boring', 241),\n",
       " ('cost', 241),\n",
       " ('friends', 239),\n",
       " ('professional', 239),\n",
       " ('programs', 239),\n",
       " ('fans', 239),\n",
       " ('unit', 239),\n",
       " ('major', 238),\n",
       " ('within', 237),\n",
       " ('mean', 237),\n",
       " ('received', 236),\n",
       " ('pc', 236),\n",
       " ('skin', 236),\n",
       " ('liked', 234),\n",
       " ('color', 234),\n",
       " ('god', 234),\n",
       " ('7', 233),\n",
       " ('record', 232),\n",
       " ('based', 232),\n",
       " ('running', 232),\n",
       " ('copy', 232),\n",
       " ('opinion', 230),\n",
       " ('early', 230),\n",
       " ('important', 230),\n",
       " ('personal', 229),\n",
       " ('totally', 229),\n",
       " ('xp', 229),\n",
       " ('tv', 229),\n",
       " ('care', 229),\n",
       " ('extra', 228),\n",
       " ('lyrics', 228),\n",
       " ('including', 228),\n",
       " ('dark', 225),\n",
       " ('house', 225),\n",
       " ('print', 224),\n",
       " ('cheap', 224),\n",
       " ('older', 223),\n",
       " ('body', 223),\n",
       " ('seemed', 223),\n",
       " ('large', 222),\n",
       " ('wait', 221),\n",
       " ('worse', 220),\n",
       " ('material', 220),\n",
       " ('drive', 220),\n",
       " ('versions', 219),\n",
       " ('ones', 219),\n",
       " ('cut', 219),\n",
       " ('online', 218),\n",
       " ('manual', 218),\n",
       " ('art', 218),\n",
       " ('daughter', 218),\n",
       " ('cool', 217),\n",
       " ('recommended', 217),\n",
       " ('30', 217),\n",
       " ('unless', 217),\n",
       " ('install', 217),\n",
       " ('woman', 216),\n",
       " ('basic', 215),\n",
       " ('included', 215),\n",
       " ('please', 215),\n",
       " ('design', 214),\n",
       " ('exactly', 214),\n",
       " ('store', 214),\n",
       " ('expect', 213),\n",
       " ('state', 213),\n",
       " ('disc', 213),\n",
       " ('due', 213),\n",
       " ('stop', 212),\n",
       " ('language', 212),\n",
       " ('turned', 212),\n",
       " ('enjoyed', 212),\n",
       " ('edition', 212),\n",
       " ('shot', 211),\n",
       " ('listening', 211),\n",
       " ('recording', 211),\n",
       " ('means', 211),\n",
       " ('cast', 211),\n",
       " ('week', 210),\n",
       " ('mr', 210),\n",
       " ('level', 210),\n",
       " ('2007', 210),\n",
       " ('ms', 209),\n",
       " ('month', 209),\n",
       " ('heart', 209),\n",
       " ('expensive', 209),\n",
       " ('form', 208),\n",
       " ('issues', 208),\n",
       " ('package', 208),\n",
       " ('child', 207),\n",
       " ('stories', 206),\n",
       " ('hit', 206),\n",
       " ('guitar', 206),\n",
       " ('title', 205),\n",
       " ('talk', 205),\n",
       " ('five', 205),\n",
       " ('country', 204),\n",
       " ('create', 204),\n",
       " ('supposed', 204),\n",
       " ('note', 204),\n",
       " ('bag', 203),\n",
       " ('terrible', 203),\n",
       " ('model', 203),\n",
       " ('group', 202),\n",
       " ('norton', 202),\n",
       " ('son', 202),\n",
       " ('horrible', 201),\n",
       " ('girl', 201),\n",
       " ('released', 201),\n",
       " ('remember', 200),\n",
       " ('100', 200),\n",
       " ('serious', 199),\n",
       " ('men', 199),\n",
       " ('except', 199),\n",
       " ('lots', 198),\n",
       " ('control', 198),\n",
       " ('stay', 198),\n",
       " ('saying', 198),\n",
       " ('wife', 197),\n",
       " ('age', 196),\n",
       " ('email', 196),\n",
       " ('production', 196),\n",
       " ('kept', 196),\n",
       " ('8', 195),\n",
       " ('spend', 195),\n",
       " ('looked', 194),\n",
       " ('agree', 194),\n",
       " ('installed', 193),\n",
       " ('room', 193),\n",
       " ('15', 193),\n",
       " ('happened', 192),\n",
       " ('process', 192),\n",
       " ('spent', 192),\n",
       " ('none', 191),\n",
       " ('strong', 191),\n",
       " ('mode', 190),\n",
       " ('dead', 189),\n",
       " ('value', 189),\n",
       " ('beginning', 189),\n",
       " ('mac', 188),\n",
       " ('decent', 187),\n",
       " ('death', 187),\n",
       " ('file', 187),\n",
       " ('soon', 186),\n",
       " ('figure', 186),\n",
       " ('despite', 186),\n",
       " ('setting', 186),\n",
       " ('internet', 185),\n",
       " ('useful', 185),\n",
       " ('oh', 185),\n",
       " ('throughout', 184),\n",
       " ('quick', 184),\n",
       " ('baby', 184),\n",
       " ('mention', 184),\n",
       " ('pro', 184),\n",
       " ('recently', 183),\n",
       " ('lives', 183),\n",
       " ('wants', 183),\n",
       " ('clean', 182),\n",
       " ('future', 182),\n",
       " ('choice', 182),\n",
       " ('message', 181),\n",
       " ('nearly', 181),\n",
       " ('horror', 181),\n",
       " ('text', 180),\n",
       " ('list', 180),\n",
       " ('format', 180),\n",
       " ('gone', 179),\n",
       " ('possible', 179),\n",
       " ('alone', 179),\n",
       " ('mother', 179),\n",
       " ('sent', 178),\n",
       " ('leave', 178),\n",
       " ('ability', 178),\n",
       " ('subject', 177),\n",
       " ('website', 177),\n",
       " ('knew', 177),\n",
       " ('issue', 177),\n",
       " ('annoying', 177),\n",
       " ('pick', 177),\n",
       " ('general', 176),\n",
       " ('whether', 176),\n",
       " ('mostly', 176),\n",
       " ('camcorder', 176),\n",
       " ('nikon', 175),\n",
       " ('awesome', 175),\n",
       " ('various', 175),\n",
       " ('late', 175),\n",
       " ('returned', 175),\n",
       " ('pop', 174),\n",
       " ('plays', 174),\n",
       " ('actors', 174),\n",
       " ('third', 173),\n",
       " ('difference', 173),\n",
       " ('hour', 173),\n",
       " ('standard', 173),\n",
       " ('director', 173),\n",
       " ('ordered', 173),\n",
       " ('similar', 172),\n",
       " ('frame', 172),\n",
       " ('market', 172),\n",
       " ('sorry', 171),\n",
       " ('guys', 171),\n",
       " ('interested', 171),\n",
       " ('easier', 171),\n",
       " ('effects', 171),\n",
       " ('result', 170),\n",
       " ('reviewers', 170),\n",
       " ('perfectly', 170),\n",
       " ('anyway', 170),\n",
       " ('known', 170),\n",
       " ('total', 170),\n",
       " ('boy', 170),\n",
       " ('settings', 170),\n",
       " ('chapter', 170),\n",
       " ('shoot', 169),\n",
       " ('usually', 169),\n",
       " ('human', 169),\n",
       " ('husband', 168),\n",
       " ('lack', 168),\n",
       " ('uses', 168),\n",
       " ('range', 168),\n",
       " ('basically', 167),\n",
       " ('feeling', 167),\n",
       " ('across', 166),\n",
       " ('girls', 165),\n",
       " ('clearly', 165),\n",
       " ('move', 165),\n",
       " ('forget', 164),\n",
       " ('role', 164),\n",
       " ('christmas', 164),\n",
       " ('research', 164),\n",
       " ('changed', 163),\n",
       " ('hot', 163),\n",
       " ('coming', 162),\n",
       " ('lenses', 162),\n",
       " ('expected', 162),\n",
       " ('beyond', 162),\n",
       " ('cards', 162),\n",
       " ('12', 162),\n",
       " ('consider', 161),\n",
       " ('mine', 161),\n",
       " ('charge', 161),\n",
       " ('giving', 160),\n",
       " ('fantastic', 160),\n",
       " ('seeing', 160),\n",
       " ('web', 160),\n",
       " ('data', 160),\n",
       " ('tool', 159),\n",
       " ('sort', 159),\n",
       " ('machine', 159),\n",
       " ('amount', 159),\n",
       " ('obviously', 159),\n",
       " ('straight', 159),\n",
       " ('addition', 158),\n",
       " ('upon', 157),\n",
       " ('musical', 157),\n",
       " ('reviewer', 157),\n",
       " ('vocals', 157),\n",
       " ('otherwise', 157),\n",
       " ('50', 156),\n",
       " ('pleased', 156),\n",
       " ('behind', 155),\n",
       " ('father', 155),\n",
       " ('compared', 155),\n",
       " ('america', 155),\n",
       " ('cause', 154),\n",
       " ('fall', 153),\n",
       " ('effort', 153),\n",
       " ('cds', 153),\n",
       " ('english', 152),\n",
       " ('interest', 152),\n",
       " ('provides', 152),\n",
       " ('parts', 151),\n",
       " ('knows', 151),\n",
       " ('red', 151),\n",
       " ('attention', 151),\n",
       " ('razor', 151),\n",
       " ('particular', 151),\n",
       " ('trip', 151),\n",
       " ('paid', 150),\n",
       " ('studio', 150),\n",
       " ('chance', 150),\n",
       " ('player', 150),\n",
       " ('wonder', 150),\n",
       " ('bring', 149),\n",
       " ('download', 149),\n",
       " ('gift', 149),\n",
       " ('wide', 149),\n",
       " ('hits', 149),\n",
       " ('speed', 149),\n",
       " ('living', 149),\n",
       " ('shaver', 148),\n",
       " ('security', 148),\n",
       " ('earlier', 148),\n",
       " ('device', 148),\n",
       " ('ways', 148),\n",
       " ('brand', 148),\n",
       " ('surprised', 147),\n",
       " ('pdf', 147),\n",
       " ('trouble', 147),\n",
       " ('artists', 147),\n",
       " ('include', 147),\n",
       " ('break', 147),\n",
       " ('stick', 146),\n",
       " ('hands', 146),\n",
       " ('offers', 146),\n",
       " ('final', 146),\n",
       " ('tax', 146),\n",
       " ('class', 145),\n",
       " ('fix', 145),\n",
       " ('thank', 145),\n",
       " ('deep', 145),\n",
       " ('average', 145),\n",
       " ('paper', 145),\n",
       " ('questions', 145),\n",
       " ('somewhat', 145),\n",
       " ('weight', 144),\n",
       " ('suggest', 144),\n",
       " ('inside', 144),\n",
       " ('accurate', 144),\n",
       " ('follow', 144),\n",
       " ('jazz', 144),\n",
       " ('apparently', 143),\n",
       " ('kid', 143),\n",
       " ('editing', 143),\n",
       " ('dr', 143),\n",
       " ('greatest', 143),\n",
       " ('ending', 143),\n",
       " ('parents', 142),\n",
       " ('stand', 142),\n",
       " ('9', 142),\n",
       " ('episode', 142),\n",
       " ('section', 142),\n",
       " ('site', 141),\n",
       " ('powerful', 141),\n",
       " ('photoshop', 141),\n",
       " ('ask', 141),\n",
       " ('front', 141),\n",
       " ('talking', 141),\n",
       " ('missing', 141),\n",
       " ('lead', 141),\n",
       " ('loves', 141),\n",
       " ('radio', 141),\n",
       " ('owned', 140),\n",
       " ('shooting', 140),\n",
       " ('offer', 140),\n",
       " ('immediately', 140),\n",
       " ('date', 140),\n",
       " ('space', 139),\n",
       " ('filter', 139),\n",
       " ('fairly', 139),\n",
       " ('feels', 139),\n",
       " ('send', 139),\n",
       " ('search', 138),\n",
       " ('shave', 138),\n",
       " ('truth', 138),\n",
       " ('career', 138),\n",
       " ('carry', 138),\n",
       " ('becomes', 138),\n",
       " ('blue', 138),\n",
       " ('present', 138),\n",
       " ('eventually', 138),\n",
       " ('learned', 138),\n",
       " ('2006', 138),\n",
       " ('key', 137),\n",
       " ('background', 137),\n",
       " ('eyes', 137),\n",
       " ('turns', 137),\n",
       " ('soundtrack', 137),\n",
       " ('bottom', 137),\n",
       " ('audio', 137),\n",
       " ('writer', 136),\n",
       " ('starts', 136),\n",
       " ('act', 136),\n",
       " ('imagine', 136),\n",
       " ('michael', 136),\n",
       " ('error', 136),\n",
       " ('provide', 135),\n",
       " ('glad', 135),\n",
       " ('normal', 135),\n",
       " ('whatever', 135),\n",
       " ('outside', 135),\n",
       " ('understanding', 135),\n",
       " ('episodes', 135),\n",
       " ('car', 134),\n",
       " ('eye', 134),\n",
       " ('option', 134),\n",
       " ('attempt', 134),\n",
       " ('watched', 134),\n",
       " ('plastic', 134),\n",
       " ('hate', 133),\n",
       " ('function', 133),\n",
       " ('lcd', 133),\n",
       " ('spanish', 133),\n",
       " ('useless', 133),\n",
       " ('mentioned', 133),\n",
       " ('rating', 132),\n",
       " ('energy', 132),\n",
       " ('considering', 132),\n",
       " ('videos', 132),\n",
       " ('question', 132),\n",
       " ('noise', 131),\n",
       " ('ideas', 131),\n",
       " ('dont', 131),\n",
       " ('certain', 130),\n",
       " ('city', 130),\n",
       " ('scale', 130),\n",
       " ('notes', 130),\n",
       " ('stupid', 130),\n",
       " ('modern', 129),\n",
       " ('minute', 129),\n",
       " ('added', 129),\n",
       " ('local', 129),\n",
       " ('stopped', 128),\n",
       " ('helpful', 128),\n",
       " ('shipping', 128),\n",
       " ('twice', 128),\n",
       " ('happen', 128),\n",
       " ('actual', 128),\n",
       " ('charger', 128),\n",
       " ('singing', 128),\n",
       " ('period', 128),\n",
       " ('appears', 127),\n",
       " ('plan', 127),\n",
       " ('flat', 127),\n",
       " ('bands', 127),\n",
       " ('step', 127),\n",
       " ('waiting', 127),\n",
       " ('artist', 126),\n",
       " ('heavy', 126),\n",
       " ('wrote', 126),\n",
       " ('disk', 126),\n",
       " ('mistake', 126),\n",
       " ('soft', 125),\n",
       " ('became', 125),\n",
       " ('instructions', 125),\n",
       " ('seconds', 125),\n",
       " ('jack', 125),\n",
       " ('c', 125),\n",
       " ('forward', 125),\n",
       " ('readers', 124),\n",
       " ('tech', 124),\n",
       " ('helps', 124),\n",
       " ('obvious', 124),\n",
       " ('avoid', 124),\n",
       " ('particularly', 123),\n",
       " ('fully', 123),\n",
       " ('recorded', 123),\n",
       " ('tries', 122),\n",
       " ('photography', 122),\n",
       " ('ended', 122),\n",
       " ('moving', 122),\n",
       " ('content', 122),\n",
       " ('computers', 122),\n",
       " ('events', 122),\n",
       " ('among', 122),\n",
       " ('negative', 122),\n",
       " ('brilliant', 121),\n",
       " ('area', 121),\n",
       " ('points', 121),\n",
       " ('positive', 121),\n",
       " ('near', 121),\n",
       " ('60', 121),\n",
       " ('regular', 121),\n",
       " ('genre', 121),\n",
       " ('miss', 121),\n",
       " ('panasonic', 121),\n",
       " ('button', 120),\n",
       " ('taste', 120),\n",
       " ('games', 120),\n",
       " ('evil', 120),\n",
       " ('users', 120),\n",
       " ('40', 120),\n",
       " ('correct', 119),\n",
       " ('stone', 119),\n",
       " ('beat', 119),\n",
       " ('six', 119),\n",
       " ('contains', 118),\n",
       " ('lines', 118),\n",
       " ('doubt', 118),\n",
       " ('allows', 118),\n",
       " ('barely', 118),\n",
       " ('kit', 118),\n",
       " ('sad', 117),\n",
       " ('tells', 117),\n",
       " ('blood', 117),\n",
       " ('provided', 117),\n",
       " ('sex', 117),\n",
       " ('interface', 117),\n",
       " ('changes', 117),\n",
       " ('performances', 117),\n",
       " ('dance', 117),\n",
       " ('touch', 116),\n",
       " ('james', 116),\n",
       " ('acrobat', 116),\n",
       " ('phone', 116),\n",
       " ('includes', 116),\n",
       " ('pieces', 116),\n",
       " ('middle', 116),\n",
       " ('higher', 116),\n",
       " ('source', 116),\n",
       " ('happens', 115),\n",
       " ('elements', 115),\n",
       " ('purchasing', 115),\n",
       " ('speak', 115),\n",
       " ('solid', 115),\n",
       " ('beats', 115),\n",
       " ('soul', 115),\n",
       " ('compact', 115),\n",
       " ('nature', 115),\n",
       " ('political', 115),\n",
       " ('telling', 114),\n",
       " ('f', 114),\n",
       " ('built', 114),\n",
       " ('b', 114),\n",
       " ('brought', 114),\n",
       " ('tale', 114),\n",
       " ('unique', 114),\n",
       " ('update', 114),\n",
       " ('latest', 114),\n",
       " ('historical', 114),\n",
       " ('science', 114),\n",
       " ('feet', 114),\n",
       " ('answer', 114),\n",
       " ('allow', 114),\n",
       " ('following', 113),\n",
       " ('fits', 113),\n",
       " ('sharp', 113),\n",
       " ('unlike', 113),\n",
       " ('la', 113),\n",
       " ('familiar', 113),\n",
       " ('expecting', 113),\n",
       " ('town', 112),\n",
       " ('details', 112),\n",
       " ('knowledge', 112),\n",
       " ('opening', 112),\n",
       " ('entertaining', 112),\n",
       " ('impossible', 112),\n",
       " ('states', 112),\n",
       " ('asked', 112),\n",
       " ('warranty', 112),\n",
       " ('pain', 112),\n",
       " ('seriously', 112),\n",
       " ('2005', 112),\n",
       " ('operating', 112),\n",
       " ('fat', 112),\n",
       " ('boys', 112),\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(data, vocab_size = 5000):\n",
    "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
    "    \n",
    "    word_count = {} # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    \n",
    "    c = Counter()\n",
    "    for words in data:\n",
    "        c.update(words)    \n",
    "    #print(c)\n",
    "    #print('')\n",
    "    \n",
    "    word_count = dict(c)\n",
    "    #print(word_count)\n",
    "    #print('')\n",
    "        \n",
    "    sorted_words = None\n",
    "    sorted_words = sorted(c, key=c.get, reverse=True)\n",
    "    #print(sorted_words)\n",
    "    \n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "    for idx, word in enumerate(sorted_words): \n",
    "        word_dict[word] = idx                            \n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_dict -> word to int\n",
    "# we will use word_dict to represent our feature vector of lenght 5000\n",
    "# word_count_dict -> total number of time a word appeared\n",
    "\n",
    "word_dict = build_dict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48193\n"
     ]
    }
   ],
   "source": [
    "print(len(word_dict)) # feature vector of lenght 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three Counter objects to store positive, negative and total counts\n",
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bought', 'album', 'loved', 'title', 'song', 'great', 'song', 'bad', 'rest', 'album', 'right', 'well', 'rest', 'songs', 'filler', 'nt', 'worth', 'money', 'paid', 'either', 'shameless', 'bubblegum', 'oversentimentalized', 'depressing', 'tripe', 'kenny', 'chesney', 'popular', 'artist', 'result', 'cookie', 'cutter', 'category', 'nashville', 'music', 'scene', 'gotta', 'pump', 'albums', 'record', 'company', 'keep', 'lining', 'pockets', 'suckers', 'keep', 'buying', 'garbage', 'perpetuate', 'garbage', 'coming', 'town', 'get', 'soapbox', 'country', 'music', 'really', 'needs', 'get', 'back', 'roots', 'stop', 'pop', 'nonsense', 'country', 'music', 'really', 'considered', 'mainstream', 'two', 'different', 'things']\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(train_X[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,words in enumerate(train_X):\n",
    "    if(train_y[i] == 'pos'):\n",
    "        positive_counts.update(words)\n",
    "        total_counts.update(words)\n",
    "    else:\n",
    "        negative_counts.update(words)\n",
    "        total_counts.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = dict(positive_counts)\n",
    "negative_counts = dict(negative_counts)\n",
    "total_counts = dict(total_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48193\n",
      "31595\n",
      "33373\n"
     ]
    }
   ],
   "source": [
    "print(len(total_counts))\n",
    "print(len(negative_counts))\n",
    "print(len(positive_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "41\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "print(positive_counts['awesome'])\n",
    "print(negative_counts['awesome'])\n",
    "print(total_counts['awesome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Probability of a word given positive class\n",
    "def pW_P(word):\n",
    "    count = 0\n",
    "    if word in positive_counts:\n",
    "        count = positive_counts[word]\n",
    "        return ((count + 1)/ (len(positive_counts) + len(total_counts)))\n",
    "    else:\n",
    "        return ((count + 1)/ (len(positive_counts) + len(total_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Probability of a word given negative class\n",
    "def pW_N(word):\n",
    "    count = 0\n",
    "    if word in negative_counts:\n",
    "        count = negative_counts[word]\n",
    "        return ((count + 1)/ (len(negative_counts) + len(total_counts)))\n",
    "    else:\n",
    "        return ((count + 1)/ (len(negative_counts) + len(total_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016551013902851679\n",
      "0.0005263949466085125\n"
     ]
    }
   ],
   "source": [
    "print(pW_P('awesome'))\n",
    "print(pW_N('awesome'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_P(prob):\n",
    "    return np.log10(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.7811753965150796\n",
      "-3.4491111671111296\n",
      "-3.2786882886011153\n"
     ]
    }
   ],
   "source": [
    "print(log_P(pW_P('awesome')))\n",
    "print(log_P(pW_P('loving')))\n",
    "print(log_P(pW_N('awesome')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = 0\n",
    "for i,word in enumerate(train_X):\n",
    "    if train_y[i] == 'pos':\n",
    "        pos_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_count = len(train_X) - pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Examples: 4847\n",
      "Negative Examples: 4684\n",
      "\n",
      "P(positive): 0.5085510439618088\n",
      "P(negative): 0.49144895603819116\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "calculate the probability of a  class being Positive and Negative(class priors)\n",
    "'''\n",
    "print(f'Positive Examples: {pos_count}')\n",
    "print(f'Negative Examples: {neg_count}')\n",
    "print()\n",
    "prior_prob_pos = (pos_count/len(train_X))\n",
    "prior_prob_neg = (neg_count/len(train_X))\n",
    "\n",
    "print(f'P(positive): {prior_prob_pos}') ## probability of being a positve class\n",
    "print(f'P(negative): {prior_prob_neg}') ## probability of being a negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log P(positive): -0.29366544982405063\n",
      "Log P(negative): -0.30852158314648437\n"
     ]
    }
   ],
   "source": [
    "'''calculate log of prababilities'''\n",
    "log_prior_prob_pos = log_P(prior_prob_pos)\n",
    "log_prior_prob_neg = log_P(prior_prob_neg)\n",
    "\n",
    "print(f'Log P(positive): {log_prior_prob_pos}')\n",
    "print(f'Log P(negative): {log_prior_prob_neg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TOTAL PROBABILITY\n",
    "\n",
    "P(C|W) = (P(W|c) * P(C)) / P(W)\n",
    "where W is the feature vector.\n",
    "aAssuming the independence consition:\n",
    "P(W|C) = P(W1|C) * P(W2|C) * P(W3|C) * .... * P(Wn|C)  (n = lenght of the fature vector) \n",
    "'''\n",
    "\n",
    "def total_prob(test,log_prior_prob_pos,log_prior_prob_neg):\n",
    "    #get a list of tokens in the given test example\n",
    "    word_tokens = rev_to_words(test)\n",
    "    print(word_tokens)\n",
    "    prob_sum_pos = 0\n",
    "    prob_sum_neg = 0\n",
    "    \n",
    "    for word in word_tokens:\n",
    "        #probability the class is postitive\n",
    "        prob_sum_pos += log_P(pW_P(word))\n",
    "        #probability the class is negative\n",
    "        prob_sum_neg += log_P(pW_N(word))\n",
    "    \n",
    "    prob_sum_pos += log_prior_prob_pos \n",
    "    prob_sum_neg += log_prior_prob_neg\n",
    "    \n",
    "    return prob_sum_pos, prob_sum_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bought', 'album', 'loved', 'title', 'song', 'great', 'song', 'bad', 'rest', 'album', 'right', 'well', 'rest', 'songs', 'filler', 'nt', 'worth', 'money', 'paid', 'either', 'shameless', 'bubblegum', 'oversentimentalized', 'depressing', 'tripe', 'kenny', 'chesney', 'popular', 'artist', 'result', 'cookie', 'cutter', 'category', 'nashville', 'music', 'scene', 'gotta', 'pump', 'albums', 'record', 'company', 'keep', 'lining', 'pockets', 'suckers', 'keep', 'buying', 'garbage', 'perpetuate', 'garbage', 'coming', 'town', 'get', 'soapbox', 'country', 'music', 'really', 'needs', 'get', 'back', 'roots', 'stop', 'pop', 'nonsense', 'country', 'music', 'really', 'considered', 'mainstream', 'two', 'different', 'things']\n"
     ]
    }
   ],
   "source": [
    "# checking if the model is working properly\n",
    "doc = \"i bought this album because i loved the title song . it 's such a great song , how bad can the rest of the album be , right ? well , the rest of the songs are just filler and are n't worth the money i paid for this . it 's either shameless bubblegum or oversentimentalized depressing tripe . kenny chesney is a popular artist and as a result he is in the cookie cutter category of the nashville music scene . he 's gotta pump out the albums so the record company can keep lining their pockets while the suckers out there keep buying this garbage to perpetuate more garbage coming out of that town . i 'll get down off my soapbox now . but country music really needs to get back to it 's roots and stop this pop nonsense . what country music really is and what it is considered to be by mainstream are two different things .\"\n",
    "pos_prob, neg_prob = total_prob(doc, log_prior_prob_pos, log_prior_prob_neg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: -218.74319562018107 \n",
      "Negative: -211.87962487725727\n"
     ]
    }
   ],
   "source": [
    "print(f'Positive: {pos_prob} \\nNegative: {neg_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a negative document\n"
     ]
    }
   ],
   "source": [
    "if pos_prob >= neg_prob:\n",
    "    print(f'This is a postive document')\n",
    "else:\n",
    "    print(f'This is a negative document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
